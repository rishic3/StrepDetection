{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  video_name   frame  Redness  Pus  Brodsky Tonsil Size  Mallampati\n",
      "0       0347  211081      2.0  0.0                  1.0         1.0\n",
      "1       0348  211365      1.0  0.0                  0.0         1.0\n",
      "2       0353  213126      1.0  0.0                  3.0         2.0\n",
      "3       0355  213761      1.0  0.0                  4.0         1.0\n",
      "4       0356  214312      2.0  2.0                  4.0         2.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"/data/datasets/rishi/symptom_classification/data/cvat_labels_12-1.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled values for Redness, Pus, Tonsil Size, Mallampati:\n",
      "135 135 135 136 \n",
      "\n",
      "redness value counts:\n",
      "2.0     60\n",
      "1.0     57\n",
      "0.0     16\n",
      "99.0     2\n",
      "Name: Redness, dtype: int64 \n",
      "\n",
      "pus value counts:\n",
      "0.0     90\n",
      "1.0     23\n",
      "2.0     13\n",
      "99.0     9\n",
      "Name: Pus, dtype: int64 \n",
      "\n",
      "tonsil size value counts:\n",
      "3.0     38\n",
      "2.0     33\n",
      "4.0     33\n",
      "1.0     22\n",
      "99.0     5\n",
      "0.0      4\n",
      "Name: Brodsky Tonsil Size, dtype: int64 \n",
      "\n",
      "mallampati value counts:\n",
      "1.0    85\n",
      "2.0    44\n",
      "3.0     7\n",
      "Name: Mallampati, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Filled values for Redness, Pus, Tonsil Size, Mallampati:\")\n",
    "print(df[df['Redness'].notnull()].shape[0], df[df['Pus'].notnull()].shape[0], df[df['Brodsky Tonsil Size'].notnull()].shape[0], df[df['Mallampati'].notnull()].shape[0], \"\\n\")\n",
    "\n",
    "# distribution of redness values:\n",
    "print(\"redness value counts:\")\n",
    "print(df[df['Redness'].notnull()]['Redness'].value_counts(), \"\\n\")\n",
    "\n",
    "# distribution of pus values:\n",
    "print(\"pus value counts:\")\n",
    "print(df[df['Pus'].notnull()]['Pus'].value_counts(), \"\\n\")\n",
    "\n",
    "# distribution of tonsil size values:\n",
    "print(\"tonsil size value counts:\")\n",
    "print(df[df['Brodsky Tonsil Size'].notnull()]['Brodsky Tonsil Size'].value_counts(), \"\\n\")\n",
    "\n",
    "# distribution of mallampati values:\n",
    "print(\"mallampati value counts:\")\n",
    "print(df[df['Mallampati'].notnull()]['Mallampati'].value_counts(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no overlap between the two datasets.\n",
      "IDs in df but not in cvat_df: {'0094', '0176', '0068', '0408', '0433', '0604', '0639-1', '0393', '0461', '0514', '0355', '0123', '0372', '0366', '0165', '0533', '0347', '0339', '0551', '0069', '0541', '0008', '0276', '0475-2', '0468', '0640', '5594-7', '0497', '0625', '0489-2', '0455', '0465-1', '0576-2', '0277', '0414-2', '0288', '0595', '0189', '0454', '0233', '0102', '0443', '0426', '5586-22', '0464', '0495', '5586-39', '0325', '0572'}\n",
      "IDs in cvat_df but not in df: {'0635', '0133', '0405', '0297', '0585', '5586-16', '0542', '0057-1', '0114', '0399', '0186', '0249', '0496', '0002', '0164', '0404', '0609', '0502', '0550', '0326', '5586-5', '0006', '0501', '0570', '5590-7', '0419', '0370', '0003', '0151', '0227', '0456', '0356', '0592', '0598', '5586-49', '0532', '5588-5', '0247', '0157', '0155', '0618', '0476', '0573', '0015', '0486', '0593-2', '0437', '0364', '6129-6', '0373', '0035', '0629', '0601', '0348', '0020-2', '0331', '0257', '5587-38', '0591', '0349', '0569-1', '0481', '0004', '0412', '0627', '0115', '0376', '0424', '0135', '0610', '0529', '0559', '0392', '0005', '0644', '0463-2', '0460-1', '0406-1', '0446', '0499', '0097', '0394', '5587-17', '6127-4', '0363', '0159', '0447', '0473', '0078', '0384', '0619', '0136-2', '0562-1', '0574', '0441', '0630', '0459', '0634', '6129-2', '0571', '0500-2', '0503-1', '0563-1', '0353', '0352', '5592-16', '0282', '0162', '0168', '0632-1', '0374', '0012', '0597'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "file_path = \"/data/datasets/rishi/symptom_classification/data/training_review_tc_3.14.23.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "SYMPTOM = 'Pus'\n",
    "\n",
    "# Remove missing entries (for now, just tonsil size)\n",
    "df = df[df[SYMPTOM] != 99]\n",
    "\n",
    "# Extract patient IDs and frame names\n",
    "df['Patient_ID'] = df['Frame Name'].str.extract(r'^(.*?)-frame_')\n",
    "df['Frame'] = df['Frame Name'].str.extract(r'(frame_\\d+)')\n",
    "# new_df = pd.read_csv('path_to_your_new_csv.csv')\n",
    "'''\n",
    "\n",
    "df = pd.read_csv('/data/datasets/rishi/symptom_classification/data/combined_test_data_Pus_1.csv')\n",
    "\n",
    "cvat_path = \"/data/datasets/rishi/symptom_classification/data/combined_train_data_Pus_1.csv\"\n",
    "cvat_df = pd.read_csv(cvat_path)\n",
    "\n",
    "# Convert 'Patient ID' and 'video_name' columns to sets\n",
    "patient_id_set = set(df['Patient_ID'])\n",
    "video_name_set = set(cvat_df['Patient_ID'])\n",
    "\n",
    "# Find the intersection of the two sets\n",
    "overlap = patient_id_set.intersection(video_name_set)\n",
    "\n",
    "# Check if there is any overlap\n",
    "if overlap:\n",
    "    print(\"There is overlap. The overlapping elements are:\", overlap)\n",
    "else:\n",
    "    print(\"There is no overlap between the two datasets.\")\n",
    "\n",
    "unique_to_df = patient_id_set.difference(video_name_set)\n",
    "\n",
    "# Find IDs unique to cvat_df (video_name_set)\n",
    "unique_to_cvat_df = video_name_set.difference(patient_id_set)\n",
    "\n",
    "# Check and print the unique IDs\n",
    "if unique_to_df:\n",
    "    print(\"IDs in df but not in cvat_df:\", unique_to_df)\n",
    "else:\n",
    "    print(\"There are no unique IDs in df compared to cvat_df.\")\n",
    "\n",
    "if unique_to_cvat_df:\n",
    "    print(\"IDs in cvat_df but not in df:\", unique_to_cvat_df)\n",
    "else:\n",
    "    print(\"There are no unique IDs in cvat_df compared to df.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique patients: 168\n",
      "before dropping duplicates: (555, 10)\n",
      "after dropping duplicates: (518, 10)\n",
      "after dropping pus 99 and null values:\n",
      "(501, 6)\n",
      "after dropping pus 99 and null values:\n",
      "(463, 6)\n",
      "Filled values for Redness, Pus, Tonsil Size, Mallampati:\n",
      "463 463 463 461 \n",
      "\n",
      "redness value counts:\n",
      "1.0     383\n",
      "0.0      61\n",
      "2.0      18\n",
      "99.0      1\n",
      "Name: Redness, dtype: int64 \n",
      "\n",
      "pus value counts:\n",
      "0.0    265\n",
      "1.0    198\n",
      "Name: Pus, dtype: int64 \n",
      "\n",
      "tonsil size value counts:\n",
      "1.0     141\n",
      "0.0      85\n",
      "3.0      76\n",
      "2.0      70\n",
      "4.0      56\n",
      "99.0     35\n",
      "Name: Tonsil Size, dtype: int64 \n",
      "\n",
      "mallampati value counts:\n",
      "1.0    240\n",
      "2.0    180\n",
      "3.0     35\n",
      "4.0      6\n",
      "Name: Mallampati, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "file_path = \"/data/datasets/rishi/symptom_classification/data/training_review_tc_3.14.23.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "SYMPTOM = 'Pus'\n",
    "SEED = 1\n",
    "\n",
    "# Remove missing entries (for now, just tonsil size)\n",
    "df = df[df[SYMPTOM] != 99]\n",
    "\n",
    "# Extract patient IDs and frame names\n",
    "df['Patient_ID'] = df['Frame Name'].str.extract(r'^(.*?)-frame_')\n",
    "df['Frame'] = df['Frame Name'].str.extract(r'(frame_\\d+)')\n",
    "\n",
    "print(\"Number of unique patients:\", len(df['Patient_ID'].unique()))\n",
    "\n",
    "# Compute the image paths based on patient IDs and frame names\n",
    "df['Image_Path'] = '/data/datasets/rishi/cropped_frames/' + df['Patient_ID'] + '/' + df['Frame'] + '.jpg'\n",
    "df = df[df['Image_Path'].apply(os.path.exists)]\n",
    "\n",
    "columns_to_keep = ['Patient_ID', 'Image_Path', 'Mallampati', 'In Focus', 'Use to Train', 'Redness', 'Pus', 'Tonsil Size', 'Strep Positive']\n",
    "df = df[columns_to_keep]\n",
    "\n",
    "# Load new data\n",
    "new_data_path = \"/data/datasets/rishi/symptom_classification/data/cvat_labels_12-1.csv\"  # Update this path\n",
    "new_df = pd.read_csv(new_data_path)\n",
    "\n",
    "# Rename columns in the new dataframe to match the existing dataframe\n",
    "new_df = new_df.rename(columns={'video_name': 'Patient_ID', 'Brodsky Tonsil Size': 'Tonsil Size'})\n",
    "\n",
    "# Compute image paths for the new dataframe\n",
    "new_df['Frame'] = 'frame_000' + new_df['frame'].astype(str)\n",
    "new_df['Image_Path'] = '/data/datasets/rishi/cropped_frames/' + new_df['Patient_ID'] + '/' + new_df['Frame'] + '.jpg'\n",
    "new_df.drop(columns=['Frame'], inplace=True)\n",
    "\n",
    "# Combine the new dataframe with the existing dataframe\n",
    "combined_df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "print(\"before dropping duplicates:\", combined_df.shape)\n",
    "\n",
    "combined_df = combined_df.drop_duplicates(subset=['Image_Path'])\n",
    "\n",
    "print(\"after dropping duplicates:\", combined_df.shape)\n",
    "\n",
    "# Filter out rows where Pus is 99 or null\n",
    "combined_df = combined_df[combined_df['Pus'].notnull() & (combined_df['Pus'] != 99)]\n",
    "\n",
    "#map pus values of 2 to 1\n",
    "def map_pus_values(val):\n",
    "    if val in [2.0]:\n",
    "        return 1.0\n",
    "    return val\n",
    "\n",
    "# Apply the function to the Pus column\n",
    "combined_df['Pus'] = combined_df['Pus'].apply(map_pus_values)\n",
    "\n",
    "#drop frame, in focus, strep positive, and use to train columns\n",
    "combined_df = combined_df.drop(columns=['frame', 'In Focus', 'Strep Positive', 'Use to Train'])\n",
    "\n",
    "print(\"after dropping pus 99 and null values:\")\n",
    "print(combined_df.shape)\n",
    "\n",
    "# Filter out rows where images don't exist\n",
    "combined_df = combined_df[combined_df['Image_Path'].apply(os.path.exists)]\n",
    "\n",
    "# Split data into train and test based on patient IDs\n",
    "patient_ids = combined_df['Patient_ID'].unique()\n",
    "train_patient_ids, test_patient_ids = train_test_split(patient_ids, test_size=0.3, random_state=SEED)\n",
    "\n",
    "train_df = combined_df[combined_df['Patient_ID'].isin(train_patient_ids)]\n",
    "test_df = combined_df[combined_df['Patient_ID'].isin(test_patient_ids)]\n",
    "\n",
    "train_csv_path = f'/data/datasets/rishi/symptom_classification/data/combined_train_data_{SYMPTOM}_{SEED}.csv'\n",
    "test_csv_path = f'/data/datasets/rishi/symptom_classification/data/combined_test_data_{SYMPTOM}_{SEED}.csv'\n",
    "\n",
    "train_df.to_csv(train_csv_path, index=False)\n",
    "test_df.to_csv(test_csv_path, index=False)\n",
    "\n",
    "print(\"after dropping pus 99 and null values:\")\n",
    "print(combined_df.shape)\n",
    "\n",
    "df = combined_df\n",
    "\n",
    "print(\"Filled values for Redness, Pus, Tonsil Size, Mallampati:\")\n",
    "print(df[df['Redness'].notnull()].shape[0], df[df['Pus'].notnull()].shape[0], df[df['Tonsil Size'].notnull()].shape[0], df[df['Mallampati'].notnull()].shape[0], \"\\n\")\n",
    "\n",
    "# distribution of redness values:\n",
    "print(\"redness value counts:\")\n",
    "print(df[df['Redness'].notnull()]['Redness'].value_counts(), \"\\n\")\n",
    "\n",
    "# distribution of pus values:\n",
    "print(\"pus value counts:\")\n",
    "print(df[df['Pus'].notnull()]['Pus'].value_counts(), \"\\n\")\n",
    "\n",
    "# distribution of tonsil size values:\n",
    "print(\"tonsil size value counts:\")\n",
    "print(df[df['Tonsil Size'].notnull()]['Tonsil Size'].value_counts(), \"\\n\")\n",
    "\n",
    "# distribution of mallampati values:\n",
    "print(\"mallampati value counts:\")\n",
    "print(df[df['Mallampati'].notnull()]['Mallampati'].value_counts(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inconsistent labels found for Patient IDs: ['0004', '0068', '0069', '0078', '0097', '0102', '0114', '0115', '0136-2', '0159', '0162', '0164', '0165', '0168', '0227', '0276', '0277', '0282', '0325', '0348', '0355', '0366', '0370', '0372', '0376', '0392', '0412', '0414-2', '0424', '0426', '0433', '0441', '0443', '0446', '0447', '0454', '0455', '0464', '0465-1', '0473', '0476', '0486', '0495', '0496', '0499', '0501', '0502', '0532', '0533', '0542', '0569-1', '0572', '0573', '0585', '0591', '0593-2', '0597', '0610', '0640', '5586-22']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming combined_df is your merged DataFrame\n",
    "\n",
    "# Define the label columns to check\n",
    "label_columns = ['Mallampati', 'Redness', 'Pus', 'Tonsil Size']\n",
    "\n",
    "df = df[df['Pus'] != 99]\n",
    "\n",
    "# Function to check if all rows in each group have the same values for label columns\n",
    "def check_label_consistency(group):\n",
    "    # Compare each label column to the first row of the group\n",
    "    for col in label_columns:\n",
    "        if not (group[col] == group.iloc[0][col]).all():\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Apply the function to each group\n",
    "consistency_check = df.groupby('Patient_ID').apply(check_label_consistency)\n",
    "\n",
    "# Find patient IDs where labels are not consistent\n",
    "inconsistent_patients = consistency_check[consistency_check == False].index.tolist()\n",
    "\n",
    "# Output the result\n",
    "if inconsistent_patients:\n",
    "    print(\"Inconsistent labels found for Patient IDs:\", inconsistent_patients)\n",
    "else:\n",
    "    print(\"All labels are consistent across rows with the same Patient_ID.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
